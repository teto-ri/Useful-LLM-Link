{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#Loader\n",
    "srcRagFileName = \"05 [참고] 2024년 블록체인 컨설팅 지원사업 수요기업 모집공고.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\myproject\\lib\\site-packages\\langchain\\embeddings\\openai.py:217: UserWarning: WARNING! temperature is not default parameter.\n",
      "                    temperature was transferred to model_kwargs.\n",
      "                    Please confirm that temperature is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "varRagDir=\"db11\"\n",
    "vectorstore = Chroma(persist_directory = varRagDir  , \n",
    "        embedding_function = \n",
    "        OpenAIEmbeddings(temperature=0\n",
    "\n",
    "            )\n",
    "        )\n",
    "print(vectorstore._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제전 컬럼수 :  4\n",
      "삭제전 리스트 건수:  6\n"
     ]
    }
   ],
   "source": [
    "#  저장된 문서가 있는지 검색\n",
    "result1 = vectorstore.get(where={\"source\": srcRagFileName})  # AI바우쳐 관련 내용\n",
    "print(\"삭제전 컬럼수 : \" , len(result1))\n",
    "print(\"삭제전 리스트 건수: \", len(result1['ids']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f659c82d-dc78-11ee-9472-30894a3f67b7\n",
      "f659c82e-dc78-11ee-8465-30894a3f67b7\n",
      "f659c82f-dc78-11ee-9db1-30894a3f67b7\n",
      "f659c830-dc78-11ee-a6e8-30894a3f67b7\n",
      "f659c831-dc78-11ee-93e1-30894a3f67b7\n",
      "f659c832-dc78-11ee-b1ce-30894a3f67b7\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(result1['ids']) ):\n",
    "    # print(i)\n",
    "    # print(result1['documents'][i])\n",
    "    print(result1['ids'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 삭제 시작!!!!\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 데이터 삭제 \n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma#update-and-delete\n",
    "print(\"데이터 삭제 시작!!!!\")\n",
    "for i in range(0, len(result1['ids']) ):\n",
    "    print(i)\n",
    "    iNum = result1['ids'][i]\n",
    "    vectorstore._collection.delete(ids=iNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제후 컬럼수 :  4\n",
      "삭제후 리스트 건수:  0\n"
     ]
    }
   ],
   "source": [
    "result2 = vectorstore.get(where={\"source\": srcRagFileName})  # AI바우쳐 관련 내용\n",
    "print(\"삭제후 컬럼수 : \" , len(result2))\n",
    "print(\"삭제후 리스트 건수: \", len(result2['ids']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상문서 RAG에 저장 \n",
    "loader = PyPDFLoader(srcRagFileName)\n",
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "varRagDBDir=\"db11\"\n",
    "vectorstore = Chroma.from_documents \\\n",
    "    (documents=all_splits, \n",
    "         embedding = \n",
    "         OpenAIEmbeddings(temperature=0\n",
    "                         \n",
    "                         ), \n",
    "           persist_directory=varRagDBDir\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장후 컬럼수 :  4\n",
      "저장후 리스트 건수:  6\n"
     ]
    }
   ],
   "source": [
    "#  저장된 문서가 있는지 검색\n",
    "result3 = vectorstore.get(where={\"source\": srcRagFileName})  # AI바우쳐 관련 내용\n",
    "print(\"저장후 컬럼수 : \" , len(result3))\n",
    "print(\"저장후 리스트 건수: \", len(result3['ids']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", \n",
    "                 temperature=0, \n",
    "                \n",
    "                )\n",
    "\n",
    "template = \"\"\" \n",
    "학습된 문서내에서 존대말로 답변해 주세요 학습된 문서내의 질문이 아니면 '질문하신 내용은 업무와 관련이 없습니다. '라고 대답해 주세요\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI바우처는 AI를 적용하고자 하는 수요기업에게 최적의 AI를 도입할 수 있도록 지원하고, 인공지능 솔루션을 개발한 공급기업에게는 새로운 시장 창출의 기회를 제공하는 사업의 일환으로, 정부가 수요기업에게 최대 2억원의 바우처를 지급하여 AI솔루션을 구매할 수 있도록 지원하는 프로그램입니다.\n"
     ]
    }
   ],
   "source": [
    "question=\"AI바우처가 뭐예요?\"\n",
    "result = qa_chain.invoke(question).content   \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "블록체인 컨설팅 지원사업은 산업 전반에서 블록체인 기술을 도입하고자 하는 기업이나 기관, 블록체인 기술을 활용하여 비즈니스를 하는 기업, 그리고 글로벌 시장에 진출하고자 하는 기업에 맞춤형 컨설팅을 제공하는 사업입니다. 이를 통해 블록체인 기술의 안정적인 성장과 글로벌 시장 진출을 지원하고자 합니다.\n"
     ]
    }
   ],
   "source": [
    "question=\"블록체인 컨설팅 지원사업이 뭐예요?\"\n",
    "result = qa_chain.invoke(question).content   \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
